{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/dhruvildave/en-fr-translation-dataset\n",
    "\n",
    "from typing import NamedTuple, Generator\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor, optim, nn\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from src.transformer import Transformer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairedSentences(NamedTuple):\n",
    "    fr: str\n",
    "    en: str\n",
    "\n",
    "class ListPairedSentences(NamedTuple):\n",
    "    fr: list[str]\n",
    "    en: list[str]\n",
    "\n",
    "    def __getitem__(self, index: int) -> PairedSentences:\n",
    "        return PairedSentences(self.fr[index], self.en[index])\n",
    "\n",
    "class TrainingBatch(NamedTuple):\n",
    "    input_ids: Tensor\n",
    "    \"\"\"In our case french\"\"\"\n",
    "    \n",
    "    encoder_mask: Tensor\n",
    "    \"\"\"basically padding tokens\"\"\"\n",
    "    \n",
    "    output_ids: Tensor\n",
    "    \"\"\"In our case english\"\"\"\n",
    "    \n",
    "    decoder_mask: Tensor\n",
    "    \"\"\"Padding tokens, don't forget to add causal mask during training\"\"\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"TrainingBatch(x.shape={self.input_ids.shape}, y.shape={self.output_ids.shape})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RollingAverage:\n",
    "    def __init__(self, window_size=1000):\n",
    "        self.window_size = window_size\n",
    "        self.losses = deque(maxlen=window_size)\n",
    "        self.sum = 0.0\n",
    "    \n",
    "    def add(self, loss_value):\n",
    "        \"\"\"Add a new loss value\"\"\"\n",
    "        # Convert tensor to float if needed\n",
    "        if torch.is_tensor(loss_value):\n",
    "            loss_value = loss_value.item()\n",
    "        \n",
    "        # If we're at capacity, subtract the value that will be removed\n",
    "        if len(self.losses) == self.window_size:\n",
    "            self.sum -= self.losses[0]\n",
    "        \n",
    "        # Add new value\n",
    "        self.losses.append(loss_value)\n",
    "        self.sum += loss_value\n",
    "    \n",
    "    def avg(self, last_n=None):\n",
    "        \"\"\"Get average of last n values (or all if n is None)\"\"\"\n",
    "        if not self.losses:\n",
    "            return 0.0\n",
    "        \n",
    "        if last_n is None:\n",
    "            return self.sum / len(self.losses)\n",
    "        \n",
    "        # Get last n values\n",
    "        n = min(last_n, len(self.losses))\n",
    "        last_values = list(self.losses)[-n:]\n",
    "        return sum(last_values) / n\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processor:\n",
    "    def __init__(self, sequence_length: int, tokenizer_name: str) -> None:\n",
    "        self._tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        self._seq_length = sequence_length\n",
    "        \n",
    "    @property\n",
    "    def tokenizer(self) -> AutoTokenizer:\n",
    "        return self._tokenizer\n",
    "\n",
    "    @property\n",
    "    def sequence_length(self) -> int:\n",
    "        return self._seq_length\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self) -> int:\n",
    "        return self._tokenizer.vocab_size\n",
    "\n",
    "    def tokenize(self, text: str, padding: str=\"max_length\", truncation:bool=True, extra: int = 0):\n",
    "        return self._tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=self._seq_length + extra,\n",
    "            padding=padding,\n",
    "            truncation=truncation)\n",
    "\n",
    "    def decode(self, token_ids: Tensor, **kwargs) -> str:\n",
    "        return self._tokenizer.decode(token_ids, **kwargs)\n",
    "\n",
    "    def make_batch(self, paired_sentences: ListPairedSentences, dtype=torch.float32) -> TrainingBatch:\n",
    "        # Tokenize each sentence in the 'fr' and 'en' lists\n",
    "        fr_sentences = [self.tokenize(sentence) for sentence in paired_sentences.fr]\n",
    "        en_sentences = [self.tokenize(sentence, extra=1) for sentence in paired_sentences.en]\n",
    "\n",
    "        # Stack tokenized tensors for batching\n",
    "        X_batch = torch.stack([x['input_ids'].squeeze(0) for x in fr_sentences])\n",
    "        Y_batch = torch.stack([y['input_ids'].squeeze(0) for y in en_sentences])\n",
    "\n",
    "        # Create encoder and decoder padding mask: 1 for real tokens, 0 for padding\n",
    "        encoder_mask = torch.stack([x['attention_mask'].squeeze(0) for x in fr_sentences]) \\\n",
    "            .unsqueeze(1).unsqueeze(2)\n",
    "        decoder_mask = torch.stack([y['attention_mask'].squeeze(0) for y in en_sentences]) \\\n",
    "            .unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        return TrainingBatch(\n",
    "            input_ids=X_batch,\n",
    "            output_ids=Y_batch,\n",
    "            encoder_mask=encoder_mask.to(dtype),\n",
    "            decoder_mask=decoder_mask.to(dtype))\n",
    "\n",
    "def get_first_masked_token(mask: torch.Tensor) -> Tensor:\n",
    "    squeezed_mask = mask.squeeze(1).squeeze(1) # mask is shaped (bs, 1, 1, sequence_length)\n",
    "    first_masked_indices = (squeezed_mask == 0).int().argmax(dim=1)\n",
    "    first_masked_indices[squeezed_mask.sum(dim=1) == squeezed_mask.size(1)] = squeezed_mask.size(1)\n",
    "    return first_masked_indices.to(dtype=torch.int32)\n",
    "\n",
    "def mask_last_token(current_mask: torch.Tensor) -> torch.Tensor:\n",
    "    first_masked_indices = get_first_masked_token(current_mask) # get the index of first masked token\n",
    "    last_token_indices = torch.clamp(first_masked_indices - 1, min=0) # to avoid negative indices\n",
    "    current_mask[torch.arange(current_mask.size(0)), 0, 0, last_token_indices] = 0 # set the last 1 token to 0\n",
    "    return current_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(csv_path: str, page: int, rows_per_page: int):\n",
    "    return pd.read_csv(csv_path, skiprows = 1 + page * rows_per_page, nrows=rows_per_page, header=None, names=[\"en\", \"fr\"])\n",
    "\n",
    "def make_generator(csv_path: str, rows_per_page: int) -> Generator[ListPairedSentences, None, None]:\n",
    "    i = 0\n",
    "    while True:\n",
    "        page = get_page(csv_path, i, rows_per_page)\n",
    "        fr_sentences = page[\"fr\"].to_list()\n",
    "        en_sentences = page[\"en\"].to_list()\n",
    "        yield ListPairedSentences(fr_sentences, en_sentences)\n",
    "        i += 1\n",
    "        \n",
    "def make_generator_v2(csv_path: str, rows_per_page: int):\n",
    "    for chunk in pd.read_csv(csv_path, chunksize=rows_per_page):\n",
    "        fr_sentences = chunk[\"fr\"].to_list()\n",
    "        en_sentences = chunk[\"en\"].to_list()\n",
    "        yield ListPairedSentences(fr_sentences, en_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype=torch.bfloat16\n",
    "csv_path = \"archive/en-fr.csv\"\n",
    "processor = Processor(200, \"bert-base-uncased\")\n",
    "d_model = 512\n",
    "model = Transformer(vocab_size=processor.vocab_size, max_sequence_len=processor.sequence_length, d_model=d_model).to(DEVICE).to(dtype)\n",
    "\n",
    "# opt and loss\n",
    "learning_rate = 3e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=processor.tokenizer.pad_token_id).to(DEVICE)\n",
    "\n",
    "# training loop qty\n",
    "num_epochs = 1\n",
    "batch_size = 48\n",
    "break_at = None # Will never break\n",
    "# get_num_steps(csv_path, batch_size) running this function is too long ... just use the cached value\n",
    "num_steps = 22520376 // batch_size\n",
    "\n",
    "num_training_steps = num_epochs * num_steps\n",
    "num_warmup_steps = 10_000\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "loss_tracker = RollingAverage(window_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 60/469174 [00:08<14:19:41,  9.09it/s, epoch loss : 10.3271 | last 1000 steps loss: 10.502118644067796 | loop error : 1.0 | lr : [1.7699999999999998e-06]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 59: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 1038/469174 [02:27<14:12:15,  9.15it/s, epoch loss : 9.2600 | last 1000 steps loss: 9.23346875 | loop error : 2.0 | lr : [3.1079999999999994e-05]]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 1037: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 2667/469174 [06:21<14:36:57,  8.87it/s, epoch loss : 7.7967 | last 1000 steps loss: 6.44809375 | loop error : 3.0 | lr : [7.992000000000001e-05]] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 2666: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|▏         | 6074/469174 [14:28<14:43:13,  8.74it/s, epoch loss : 6.7251 | last 1000 steps loss: 5.49184375 | loop error : 4.0 | lr : [0.00018209999999999998]] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 6073: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|▏         | 6400/469174 [15:15<13:59:34,  9.19it/s, epoch loss : 6.6573 | last 1000 steps loss: 5.373828125 | loop error : 5.0 | lr : [0.00019184999999999997]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 6399: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|▏         | 6439/469174 [15:20<14:05:48,  9.12it/s, epoch loss : 6.6573 | last 1000 steps loss: 5.414390625 | loop error : 6.0 | lr : [0.00019298999999999998]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 6438: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|▏         | 6446/469174 [15:21<11:13:31, 11.45it/s, epoch loss : 6.6546 | last 1000 steps loss: 5.416171875 | loop error : 8.0 | lr : [0.00019313999999999998]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 6444: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n",
      "Error in batch 6445: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|▏         | 6528/469174 [15:33<14:03:25,  9.14it/s, epoch loss : 6.6473 | last 1000 steps loss: 5.491828125 | loop error : 9.0 | lr : [0.00019557]]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 6527: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|▏         | 6756/469174 [16:05<14:09:57,  9.07it/s, epoch loss : 6.6064 | last 1000 steps loss: 5.54071875 | loop error : 10.0 | lr : [0.00020237999999999997]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 6755: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 7795/469174 [18:35<14:40:20,  8.73it/s, epoch loss : 6.3901 | last 1000 steps loss: 4.986578125 | loop error : 11.0 | lr : [0.00023351999999999997]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 7794: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 7807/469174 [18:36<13:59:23,  9.16it/s, epoch loss : 6.3867 | last 1000 steps loss: 4.98290625 | loop error : 12.0 | lr : [0.00023384999999999997]] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 7806: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 8525/469174 [20:20<14:15:40,  8.97it/s, epoch loss : 6.2945 | last 1000 steps loss: 5.16434375 | loop error : 13.0 | lr : [0.00025535999999999994]] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 8524: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 11519/469174 [27:31<14:06:22,  9.01it/s, epoch loss : 5.9613 | last 1000 steps loss: 4.855953125 | loop error : 14.0 | lr : [0.0002990167126187458]] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 11518: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 15810/469174 [37:48<14:02:19,  8.97it/s, epoch loss : 5.5930 | last 1000 steps loss: 4.769203125 | loop error : 15.0 | lr : [0.00029621385357184854]] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 15809: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 15815/469174 [37:49<13:33:01,  9.29it/s, epoch loss : 5.5921 | last 1000 steps loss: 4.766734375 | loop error : 16.0 | lr : [0.00029621124018345987]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 15814: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 17738/469174 [42:24<13:26:28,  9.33it/s, epoch loss : 5.4325 | last 1000 steps loss: 3.83525 | loop error : 17.0 | lr : [0.0002949555070626821]]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 17737: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 17776/469174 [42:30<14:08:23,  8.87it/s, epoch loss : 5.4290 | last 1000 steps loss: 3.82659375 | loop error : 18.0 | lr : [0.00029493133322008646]] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 17775: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 18229/469174 [43:34<11:34:36, 10.82it/s, epoch loss : 5.3924 | last 1000 steps loss: 3.927421875 | loop error : 20.0 | lr : [0.00029463667367925884]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 18227: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n",
      "Error in batch 18228: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 19464/469174 [46:32<13:44:04,  9.10it/s, epoch loss : 5.2774 | last 1000 steps loss: 3.522390625 | loop error : 21.0 | lr : [0.0002938304433613401]] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 19463: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▍         | 22759/469174 [54:27<13:57:50,  8.88it/s, epoch loss : 5.1063 | last 1000 steps loss: 4.18596875 | loop error : 22.0 | lr : [0.000291678318023233]]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 22758: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▍         | 22768/469174 [54:28<14:06:15,  8.79it/s, epoch loss : 5.1056 | last 1000 steps loss: 4.18396875 | loop error : 23.0 | lr : [0.0002916730912464556]]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 22767: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▍         | 23210/469174 [55:32<13:34:03,  9.13it/s, epoch loss : 5.0849 | last 1000 steps loss: 4.1025 | loop error : 24.0 | lr : [0.00029138496517659967]]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 23209: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n",
      "Error in batch 23211: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▌         | 24012/469174 [57:31<13:45:42,  8.99it/s, epoch loss : 5.0545 | last 1000 steps loss: 4.15996875 | loop error : 26.0 | lr : [0.0002908622874988566]]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 24011: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▌         | 24270/469174 [58:08<13:41:15,  9.03it/s, epoch loss : 5.0408 | last 1000 steps loss: 4.06459375 | loop error : 27.0 | lr : [0.0002906943772948817]]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 24269: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▌         | 24291/469174 [58:11<13:22:56,  9.23it/s, epoch loss : 5.0404 | last 1000 steps loss: 4.07509375 | loop error : 28.0 | lr : [0.0002906813103529381]]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 24290: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▌         | 24325/469174 [58:15<13:23:15,  9.23it/s, epoch loss : 5.0403 | last 1000 steps loss: 4.080078125 | loop error : 29.0 | lr : [0.0002906597498987312]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 24324: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▌         | 24342/469174 [58:17<13:35:50,  9.09it/s, epoch loss : 5.0396 | last 1000 steps loss: 4.070765625 | loop error : 30.0 | lr : [0.0002906492963451763]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 24341: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▌         | 24359/469174 [58:20<13:45:49,  8.98it/s, epoch loss : 5.0391 | last 1000 steps loss: 4.0708125 | loop error : 31.0 | lr : [0.00029063884279162145]]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 24358: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▌         | 24372/469174 [58:21<13:44:55,  8.99it/s, epoch loss : 5.0386 | last 1000 steps loss: 4.069984375 | loop error : 32.0 | lr : [0.0002906310026264553]] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 24371: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▌         | 24429/469174 [58:29<13:28:37,  9.17it/s, epoch loss : 5.0381 | last 1000 steps loss: 4.071890625 | loop error : 33.0 | lr : [0.0002905944151890133]] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 24428: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▌         | 24842/469174 [59:29<18:26:05,  6.70it/s, epoch loss : 5.0185 | last 1000 steps loss: 4.029265625 | loop error : 34.0 | lr : [0.0002903252361849756]] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 24841: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6%|▌         | 26812/469174 [1:04:15<13:32:34,  9.07it/s, epoch loss : 4.8976 | last 1000 steps loss: 3.3587109375 | loop error : 35.0 | lr : [0.00028903879575063046]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 26811: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   9%|▉         | 43692/469174 [1:44:23<13:14:18,  8.93it/s, epoch loss : 4.4112 | last 1000 steps loss: 4.507796875 | loop error : 36.0 | lr : [0.0002780109500973487]]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 43691: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|▉         | 44942/469174 [1:47:21<12:23:48,  9.51it/s, epoch loss : 4.3937 | last 1000 steps loss: 3.752875 | loop error : 37.0 | lr : [0.0002771949195729723]]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 44941: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|█         | 48774/469174 [1:56:35<13:02:23,  8.96it/s, epoch loss : 4.3726 | last 1000 steps loss: 4.05690625 | loop error : 38.0 | lr : [0.00027469194684368015]] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in batch 48773: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11%|█▏        | 52849/469174 [2:06:19<16:35:09,  6.97it/s, epoch loss : 4.3253 | last 1000 steps loss: 4.2942890625 | loop error : 38.0 | lr : [0.00027202955742267634]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     39\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 40\u001b[0m output_probs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_decoder_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# flatten target and outputprobs to compute cce loss\u001b[39;00m\n\u001b[1;32m     47\u001b[0m output_probs_flat \u001b[38;5;241m=\u001b[39m output_probs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output_probs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/workspace/src/transformer.py:145\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, inputs, outputs, encoder_mask, decoder_mask)\u001b[0m\n\u001b[1;32m    143\u001b[0m x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding[:, :outputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), :]\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder:\n\u001b[0;32m--> 145\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# apply a final linear layer\u001b[39;00m\n\u001b[1;32m    148\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_output(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/workspace/src/transformer.py:67\u001b[0m, in \u001b[0;36mNxDecoderBlock.forward\u001b[0;34m(self, x, encoder_output, mask)\u001b[0m\n\u001b[1;32m     64\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_and_norm1(x, self_attention_output)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Cross-attention with add & norm\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m cross_attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m cross_attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(cross_attention_output)\n\u001b[1;32m     69\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_and_norm2(x, cross_attention_output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/workspace/src/multi_head_attention.py:30\u001b[0m, in \u001b[0;36mMultiHeadAttentionLayer.forward\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Start with linear projection\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Shape: (batch_size, seq_length, d_model)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_q(q)\n\u001b[0;32m---> 30\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_k\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_v(v)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Reshaping\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Shape: (batch_size, num_heads, seq_length, head_dim)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    model.to(DEVICE)\n",
    "    epoch_loss = 0.0\n",
    "    loop_error = 0.0\n",
    "\n",
    "    # Reset generator at the start of each epoch\n",
    "    progress_bar = tqdm(make_generator_v2(csv_path, batch_size), total=num_steps)\n",
    "    progress_bar.set_description(f\"Epoch {epoch + 1}\")\n",
    "\n",
    "    for step, raw_batch in enumerate(progress_bar, start=1):\n",
    "        try:\n",
    "            training_batch = processor.make_batch(raw_batch, dtype)        # Converts batch to `TrainingBatch` format\n",
    "            input_ids = training_batch.input_ids.to(DEVICE)            # Encoder input (source sentence)\n",
    "            target_ids = training_batch.output_ids.to(DEVICE)          # Decoder target sequence\n",
    "            encoder_mask = training_batch.encoder_mask.to(DEVICE)   # Mask for encoder\n",
    "\n",
    "            # adjust decoder input\n",
    "            decoder_input_ids = target_ids[:, :-1]\n",
    "            target_ids_flat = target_ids[:, 1:].contiguous().view(-1)\n",
    "\n",
    "            # adjust decoder mask too\n",
    "            decoder_mask = training_batch.decoder_mask[:, :, :, :-1].to(DEVICE)\n",
    "            \n",
    "            # We need to create a causal mask too\n",
    "            seq_len = decoder_input_ids.shape[1]\n",
    "            causal_mask = torch.tril(torch.ones((seq_len, seq_len))).to(DEVICE).to(dtype)\n",
    "            \n",
    "            # final decoder mask as prod of padding * causal\n",
    "            final_decoder_mask = decoder_mask * causal_mask.unsqueeze(0)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch {step}: {e}\")\n",
    "            loop_error += 1\n",
    "            continue\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output_probs = model(\n",
    "            input_ids,\n",
    "            decoder_input_ids,\n",
    "            encoder_mask=encoder_mask,\n",
    "            decoder_mask=final_decoder_mask)\n",
    "\n",
    "        # flatten target and outputprobs to compute cce loss\n",
    "        output_probs_flat = output_probs.view(-1, output_probs.size(-1))\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(output_probs_flat, target_ids_flat)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Track loss\n",
    "        loss_tracker.add(loss.item())\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Optionally, print progress\n",
    "        progress_bar.set_postfix_str(f\"epoch loss : {epoch_loss / step:.4f} | \"\n",
    "                                     f\"last {loss_tracker.window_size} steps loss: {loss_tracker.avg()} | \"\n",
    "                                     f\"loop error : {loop_error} | \"\n",
    "                                     f\"lr : {scheduler.get_lr()}\")\n",
    "        \n",
    "        \n",
    "        if step == break_at: # train only on a subset for now\n",
    "            break\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     sample_output = output_probs.argmax(dim=-1)\n",
    "    #     print(\"Predicted tokens:\", sample_output[0, :10].squeeze())  \n",
    "    #     print(\"Target tokens:   \", target_ids[0, 1:11].squeeze())  \n",
    "\n",
    "    # Print average loss per epoch\n",
    "    # print(f\"Epoch [{epoch+1}/{num_epochs}] completed, Average Loss: {epoch_loss / num_steps:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def infer(model: nn.Module, \n",
    "          processor: Processor, \n",
    "          french_sentence: str, \n",
    "          max_length: int | None = None, \n",
    "          skip_special_tokens: bool = True,\n",
    "          dtype = torch.float32) -> str:\n",
    "    # first model as eval (we don't train here)\n",
    "    model.eval()\n",
    "    sequence_length = max_length if max_length else processor.sequence_length\n",
    "\n",
    "    # Tokenize the input sequence in french\n",
    "    tokens = processor.tokenize(french_sentence)\n",
    "\n",
    "    # create the encoder input and mask\n",
    "    encoder_ids = tokens[\"input_ids\"].int().to(DEVICE)\n",
    "    encoder_mask = tokens[\"attention_mask\"].unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    # Create padding mask for current sequence length\n",
    "    padding_mask = torch.zeros((1, 1, 1, sequence_length), dtype=dtype).to(DEVICE)\n",
    "    causal_mask = (\n",
    "        torch.tril(torch.ones((sequence_length, sequence_length), dtype=dtype))\n",
    "        .unsqueeze(0)\n",
    "        .to(DEVICE)\n",
    "    )\n",
    "\n",
    "    # Initialize decoder input with just the start token\n",
    "    generated_ids = torch.zeros((1, sequence_length), dtype=torch.int).to(DEVICE)\n",
    "    generated_ids[0, 0] = processor.tokenizer.cls_token_id\n",
    "    \n",
    "    # loop to generate output ids\n",
    "    for idx in range(1, sequence_length):\n",
    "        padding_mask[0, 0, :idx, :idx + 1] = 1.0  # All positions up to current length are unmasked\n",
    "        final_mask = padding_mask * causal_mask\n",
    "        # return\n",
    "        output_probs = model(\n",
    "            encoder_ids,\n",
    "            generated_ids,\n",
    "            encoder_mask=encoder_mask,\n",
    "            decoder_mask=final_mask)\n",
    "\n",
    "        # Select next token from the LAST position (current_len - 1)\n",
    "        next_token_id = output_probs[0, idx-1, :].argmax(dim=-1)  # Last position, all vocab\n",
    "        \n",
    "        # Append the new token\n",
    "        generated_ids[0, idx] = next_token_id\n",
    "\n",
    "        # early stop when encounter sep_token_id\n",
    "        if next_token_id.item() == processor.tokenizer.sep_token_id:\n",
    "            break\n",
    "\n",
    "    return processor.decode(generated_ids[0], skip_special_tokens=skip_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = make_generator(csv_path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Observatoires Depuis des milliers d'années, les autochtones observent les étoiles pour se repérer dans l'espace et le temps.\"]\n",
      "['Observatories For thousands of years, native people use the stars to navigate and to monitor the passage of time.']\n",
      "since the last year, the aboriginal peoples has been able to provide a variety of information on the energy and energy efficiency of the environment.\n"
     ]
    }
   ],
   "source": [
    "sentence = next(sentences)\n",
    "print(sentence.fr) \n",
    "print(sentence.en)\n",
    "print(infer(model, processor, sentence.fr[0], dtype=dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hsi\n"
     ]
    }
   ],
   "source": [
    "sentence = input(\"Any sentence: \")\n",
    "print(infer(model, processor, sentence, dtype=dtype))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
