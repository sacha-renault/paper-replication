{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/dhruvildave/en-fr-translation-dataset\n",
    "from typing import Generator\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import Tensor, optim\n",
    "from tqdm import tqdm\n",
    "from src.transformer import Transformer\n",
    "from src.processor import SentenceProcessor, ListPairedSentences, make_generator_v2\n",
    "from src.light import LitTransformer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from collections import deque\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RollingAverage:\n",
    "    def __init__(self, window_size=1000):\n",
    "        self.window_size = window_size\n",
    "        self.losses = deque(maxlen=window_size)\n",
    "        self.sum = 0.0\n",
    "    \n",
    "    def add(self, loss_value):\n",
    "        \"\"\"Add a new loss value\"\"\"\n",
    "        # Convert tensor to float if needed\n",
    "        if torch.is_tensor(loss_value):\n",
    "            loss_value = loss_value.item()\n",
    "        \n",
    "        # If we're at capacity, subtract the value that will be removed\n",
    "        if len(self.losses) == self.window_size:\n",
    "            self.sum -= self.losses[0]\n",
    "        \n",
    "        # Add new value\n",
    "        self.losses.append(loss_value)\n",
    "        self.sum += loss_value\n",
    "    \n",
    "    def avg(self, last_n=None):\n",
    "        \"\"\"Get average of last n values (or all if n is None)\"\"\"\n",
    "        if not self.losses:\n",
    "            return 0.0\n",
    "        \n",
    "        if last_n is None:\n",
    "            return self.sum / len(self.losses)\n",
    "        \n",
    "        # Get last n values\n",
    "        n = min(last_n, len(self.losses))\n",
    "        last_values = list(self.losses)[-n:]\n",
    "        return sum(last_values) / n\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_masked_token(mask: torch.Tensor) -> Tensor:\n",
    "    squeezed_mask = mask.squeeze(1).squeeze(1) # mask is shaped (bs, 1, 1, sequence_length)\n",
    "    first_masked_indices = (squeezed_mask == 0).int().argmax(dim=1)\n",
    "    first_masked_indices[squeezed_mask.sum(dim=1) == squeezed_mask.size(1)] = squeezed_mask.size(1)\n",
    "    return first_masked_indices.to(dtype=torch.int32)\n",
    "\n",
    "def mask_last_token(current_mask: torch.Tensor) -> torch.Tensor:\n",
    "    first_masked_indices = get_first_masked_token(current_mask) # get the index of first masked token\n",
    "    last_token_indices = torch.clamp(first_masked_indices - 1, min=0) # to avoid negative indices\n",
    "    current_mask[torch.arange(current_mask.size(0)), 0, 0, last_token_indices] = 0 # set the last 1 token to 0\n",
    "    return current_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(csv_path: str, page: int, rows_per_page: int):\n",
    "    return pd.read_csv(csv_path, skiprows = 1 + page * rows_per_page, nrows=rows_per_page, header=None, names=[\"en\", \"fr\"])\n",
    "\n",
    "def make_generator(csv_path: str, rows_per_page: int) -> Generator[ListPairedSentences, None, None]:\n",
    "    i = 0\n",
    "    while True:\n",
    "        page = get_page(csv_path, i, rows_per_page)\n",
    "        fr_sentences = page[\"fr\"].to_list()\n",
    "        en_sentences = page[\"en\"].to_list()\n",
    "        yield ListPairedSentences(fr_sentences, en_sentences)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype=torch.bfloat16\n",
    "csv_path = \"archive/en-fr.csv\"\n",
    "processor = SentenceProcessor(200, \"bert-base-uncased\")\n",
    "d_model = 512\n",
    "model = Transformer(vocab_size=processor.vocab_size, max_sequence_len=processor.sequence_length, d_model=d_model).to(DEVICE).to(dtype)\n",
    "\n",
    "# opt and loss\n",
    "learning_rate = 3e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# training loop qty\n",
    "num_epochs = 1\n",
    "batch_size = 48\n",
    "break_at = None # Will never break\n",
    "# get_num_steps(csv_path, batch_size) running this function is too long ... just use the cached value\n",
    "num_steps = 22520376 // batch_size\n",
    "\n",
    "num_training_steps = num_epochs * num_steps\n",
    "num_warmup_steps = 10_000\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "loss_tracker = RollingAverage(window_size=1000)\n",
    "\n",
    "lit_model = LitTransformer(\n",
    "    model, \n",
    "    processor,\n",
    "    optimizer = optim.Adam,\n",
    "    optimizer_kwargs= { 'lr': learning_rate },\n",
    "    scheduler=get_linear_schedule_with_warmup,\n",
    "    scheduler_kwargs={\n",
    "        \"num_warmup_steps\": num_warmup_steps,\n",
    "        \"num_training_steps\": num_training_steps\n",
    "    }\n",
    ").to(DEVICE).to(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | _model   | Transformer      | 91.1 M | train\n",
      "1 | _loss_fn | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "91.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "91.1 M    Total params\n",
      "364.203   Total estimated model params size (MB)\n",
      "235       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4586b5f14647e991b05699d9f7343d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lightning as L\n",
    "\n",
    "class CSVDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, csv_path: str, batch_size: int):\n",
    "        self.csv_path = csv_path\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        return make_generator_v2(self.csv_path, self.batch_size)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    limit_train_batches=num_steps,\n",
    "    max_epochs=num_epochs,\n",
    "    accumulate_grad_batches=4,\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=CSVDataset(\"archive/en-fr.csv\", batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = make_generator(csv_path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['La dÃ©couverte du spectre de la lumiÃ¨re blanche Des codes dans la lumiÃ¨re Le spectre Ã©lectromagnÃ©tique Les spectres dâ€™Ã©mission Les spectres dâ€™absorption Les annÃ©es-lumiÃ¨re La pollution lumineuse']\n",
      "['The white light spectrum Codes in the light The electromagnetic spectrum Emission spectra Absorption spectra Light-years Light pollution']\n",
      "the white light spectrum codes in the light the electromagnetic spectrum emission spectra absorption spectra light - years light pollution\n"
     ]
    }
   ],
   "source": [
    "sentence = next(sentences)\n",
    "print(sentence.fr) \n",
    "print(sentence.en)\n",
    "print(lit_model.translate(sentence.fr[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
